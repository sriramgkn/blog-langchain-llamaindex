{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring LangChain and LlamaIndex\n",
        "\n",
        "Cite like this [[0](#ref-0)].\n",
        "Jupyter instructions: install [langchain](https://python.langchain.com/docs/get_started/installation/) and [llama-index](https://docs.llamaindex.ai/en/stable/getting_started/installation/) in your python environment.\n",
        "\n",
        "In this post, we will explore [LangChain](https://www.langchain.com/) and [LlamaIndex](https://www.llamaindex.ai/) - two popular frameworks to help with application development using large language models in Python.\n",
        "\n",
        "## LangChain\n",
        "\n",
        "LangChain is an open-source framework designed to simplify the development of applications using large language models (LLMs). At its core, LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications [[1](#ref-1)] [[2](#ref-2)].\n",
        "\n",
        "Some key concepts in LangChain include:\n",
        "\n",
        "- Components: Modular building blocks that are easy to use, like LLM wrappers, prompt templates, and vector stores [[2](#ref-2)] [[8](#ref-8)]\n",
        "- Chains: Combine multiple components together to accomplish a specific task, making it easier to implement complex applications [[2](#ref-2)] [[8](#ref-8)]\n",
        "- Agents: Allow LLMs to interact with their environment by making decisions about actions to take [[2](#ref-2)] [[8](#ref-8)]\n",
        "\n",
        "Here's an example of using LangChain to create a simple prompt template and LLM chain:\n",
        "\n"
      ],
      "metadata": {
        "id": "LcZ68UjXQ6om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, OpenAI, LLMChain\n",
        "\n",
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "question = \"What is the capital of France?\"\n",
        "\n",
        "print(llm_chain.run(question))"
      ],
      "metadata": {
        "id": "HGn4q2Xy1eSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will output a step-by-step answer to the question \"What is the capital of France?\" using the OpenAI LLM [[11](#ref-11)].\n",
        "\n",
        "LangChain also provides capabilities for working with documents, including:\n",
        "\n",
        "- Document loaders to load data into documents\n",
        "- Text splitters to chunk long text\n",
        "- Embeddings and vector stores to store and retrieve relevant documents [[11](#ref-11)]\n",
        "\n",
        "## LlamaIndex\n",
        "\n",
        "LlamaIndex (formerly GPT Index) is a project that provides a central interface to connect your LLM's with external data. It provides data structures to make it easier to work with textual data [[3](#ref-3)].\n",
        "\n",
        "Some key features of LlamaIndex include:\n",
        "\n",
        "- A suite of in-memory indices over your unstructured and structured data for use with LLMs\n",
        "- Offers a comprehensive toolset trading off cost and performance\n",
        "- Provides data connectors to your common data sources and data formats\n",
        "- Provides indices that can be used for various LLM tasks such as question-answering, summarization, and text generation [[3](#ref-3)]\n",
        "\n",
        "Here's an example of using LlamaIndex to build a simple question answering system over a set of documents:"
      ],
      "metadata": {
        "id": "7R-XZTK9SzQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import SimpleDirectoryReader, GPTListIndex, readers, GPTSimpleVectorIndex, LLMPredictor, PromptHelper\n",
        "from langchain import OpenAI\n",
        "\n",
        "# Load documents\n",
        "documents = SimpleDirectoryReader('data').load_data()\n",
        "\n",
        "# Create an index of the documents\n",
        "index = GPTSimpleVectorIndex(documents)\n",
        "\n",
        "# Create a question answering system\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "# Ask a question\n",
        "response = query_engine.query(\"What did the author do growing up?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "DHon_8YWS7T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This loads a set of documents, creates a vector index, and uses it to answer a question about the author's childhood based on the documents [[3](#ref-3)].\n",
        "\n",
        "In summary, LangChain and LlamaIndex are two powerful open-source libraries that make it easier to build applications with large language models by providing abstractions and integrations for common tasks and data sources. LangChain focuses more on chaining LLM components together, while LlamaIndex specializes in connecting LLMs with external data through in-memory indices."
      ],
      "metadata": {
        "id": "Lco1R7_TS8gq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### References  \n",
        "[0] <a id=\"ref-0\"></a> [https://www.example.com](https://www.example.com)  \n",
        "[1] <a id=\"ref-1\"></a> [techtarget.com: What Is LangChain and How to Use It: A Guide](https://www.techtarget.com/searchenterpriseai/definition/LangChain)  \n",
        "[2] <a id=\"ref-2\"></a> [langchain.com: Introduction to LangChain](https://js.langchain.com/docs/get_started/introduction)  \n",
        "[3] <a id=\"ref-3\"></a> [nanonets.com: LangChain: A Complete Guide & Tutorial](https://nanonets.com/blog/langchain/)  \n",
        "[4] <a id=\"ref-4\"></a> [geeksforgeeks.org: Introduction to LangChain](https://www.geeksforgeeks.org/introduction-to-langchain/)  \n",
        "[5] <a id=\"ref-5\"></a> [enterprisedna.co: What is LangChain? A Beginner's Guide with Examples](https://blog.enterprisedna.co/what-is-langchain-a-beginners-guide-with-examples/)  \n",
        "[6] <a id=\"ref-6\"></a> [ibm.com: What is LangChain?](https://www.ibm.com/topics/langchain)  \n",
        "[7] <a id=\"ref-7\"></a> [pinecone.io: LangChain Intro: What is LangChain?](https://www.pinecone.io/learn/series/langchain/langchain-intro/)  \n",
        "[8] <a id=\"ref-8\"></a> [github.com: LangChain Examples](https://github.com/alphasecio/langchain-examples)  \n",
        "[9] <a id=\"ref-9\"></a> [github.com: LangChain Repository](https://github.com/langchain-ai/langchain)  \n",
        "[10] <a id=\"ref-10\"></a> [langchain.com: LangChain Cookbook](https://python.langchain.com/cookbook/)  \n",
        "[11] <a id=\"ref-11\"></a> [python-engineer.com: LangChain Crash Course](https://www.python-engineer.com/posts/langchain-crash-course/)  \n",
        "[12] <a id=\"ref-12\"></a> [langchain.com: Code Writing with LangChain](https://python.langchain.com/docs/expression_language/cookbook/code_writing/)  \n",
        "[13] <a id=\"ref-13\"></a> [sitepoint.com: LangChain Python: The Complete Guide](https://www.sitepoint.com/langchain-python-complete-guide/)  \n",
        "[14] <a id=\"ref-14\"></a> [semaphoreci.com: LangChain: A Beginner's Guide](https://semaphoreci.com/blog/langchain)  \n",
        "[15] <a id=\"ref-15\"></a> [youtube.com: LangChain Crash Course - Build Apps with Language Models](https://www.youtube.com/watch?v=aywZrzNaKjs)  \n",
        "\n",
        "_Assisted by claude-3-opus on [perplexity.ai](https://perplexity.ai)_"
      ],
      "metadata": {
        "id": "TULMR03mRFk4"
      }
    }
  ]
}